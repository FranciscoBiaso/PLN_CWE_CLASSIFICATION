# Classificador de Vulnerabilidades CWE

## √çndice

- [Objetivo do Projeto](#objetivo-do-projeto)
- [Descri√ß√£o dos Scripts](#descri√ß√£o-dos-scripts)
  - [Carregar e Processar Conjuntos de Dados](#carregar-e-processar-conjuntos-de-dados)
  - [Pipeline de Treinamento](#pipeline-de-treinamento)
  - [Classificador](#classificador)
- [Pipelines](#pipelines)
  - [Pipeline do Script `load_and_process_cwe_datasets.py`](#pipeline-do-script-load_and_process_cwe_datasetspy)
  - [Pipeline do Script `train_cwe_model.py`](#pipeline-do-script-train_cwe_modelpy)
- [Descri√ß√£o T√©cnica](#descri√ß√£o-t√©cnica)
  - [Vetoriza√ß√£o com Tree-Sitter e Word2Vec](#vetoriza√ß√£o-com-tree-sitter-e-word2vec)
- [Melhorias no Projeto - Pr√©-processamento](#melhorias-no-projeto---pr√©-processamento)
  - [Modo 1: Foco nos Identificadores](#modo-1-foco-nos-identificadores)
  - [Modo 2: Embeddings Enriquecidos](#modo-2-embeddings-enriquecidos)
  - [Benef√≠cios](#benef√≠cios)
- [Apresenta√ß√£o e Trabalho](#apresenta√ß√£o-e-trabalho)
  - [Modelo Random Forest](#modelo-random-forest)
  - [Resultados Finais (m√©tricas)](#resultados-finais-m√©tricas)
  - [Adicionando Estratifica√ß√£o](#adicionando-estratifica√ß√£o)
- [Descri√ß√£o dos Par√¢metros](#descri√ß√£o-dos-par√¢metros)
- [Base de Dados](#base-de-dados)
- [Depend√™ncias](#depend√™ncias)
  - [Instala√ß√£o das Depend√™ncias](#instala√ß√£o-das-depend√™ncias)

## Objetivo do Projeto

Este projeto tem como objetivo classificar falhas de seguran√ßa em c√≥digos C/C++ utilizando modelos de aprendizado de m√°quina. O sistema foi desenvolvido para identificar vulnerabilidades a partir de um conjunto de falhas previamente treinadas, utilizando dois tipos de modelo: Random Forest e Codebert.

## Descri√ß√£o dos Scripts

1. **Carregar e Processar Conjuntos de Dados (`load_and_process_cwe_datasets.py`):**  
   Este script realiza o carregamento e o processamento de arquivos de c√≥digo C/C++, utilizando a biblioteca Tree-Sitter para analisar a estrutura sint√°tica e extrair tokens relevantes. Ele associa r√≥tulos de vulnerabilidades (CWE) aos c√≥digos com base em suas categorias e organiza os dados em um formato estruturado. Al√©m disso, o script salva os dados processados em arquivos JSON, prontos para serem utilizados em etapas posteriores, como treinamento de modelos de classifica√ß√£o. O objetivo √© criar uma base s√≥lida para identificar e classificar falhas de seguran√ßa de maneira eficiente.

   **Execu√ß√£o:**
   ```
   python3 load_and_process_cwe_datasets.py --base_path <diret√≥rio_dos_dados> --minFiles <n√∫mero_m√≠nimo_de_arquivos> --maxFiles <n√∫mero_m√°ximo_de_arquivos>
   ```
   1.1 Exemplo de Dados Processados  

   Ap√≥s o processamento de um arquivo de c√≥digo C/C++, o script gera tokens que representam os elementos relevantes do c√≥digo. Esses tokens incluem identificadores, literais, diretivas de pr√©-processador e outros componentes sint√°ticos importantes. Abaixo, apresentamos um exemplo do formato dos dados processados:  

   ```json
   {
      "code": [
         "#include \"std_testcase.h\"",
         "\"std_testcase.h\"",
         "#ifndef _WIN32\n#include <wchar.h>\n#endif",
         "_WIN32",
         "#include <wchar.h",
         "#define SRC_STRING \"AAAAAAAAAA\"",
         "SRC_STRING",
         "\"AAAAAAAAAA\"",
         "namespace",
         "CWE122_Heap_Based_Buffer_Overflow__cpp_CWE193_char_ncpy_54",
         "#ifndef OMITBAD",
         "badSink_d",
         "data",
         "badSink_c",
         "data",
         "badSink_d",
         "data",
         "#ifndef OMITGOOD",
         "goodG2BSink_d",
         "data",
         "goodG2BSink_c",
         "data",
         "goodG2BSink_d",
         "data"
      ]
   }
   ```

   1.2 R√≥tulos de vunerabilidade

   ```json
   {
      "CWE122_Heap_Based_Buffer_Overflow": 0,
      "CWE124_Buffer_Underwrite": 1,
      "CWE126_Buffer_Overread": 2,
      "CWE127_Buffer_Underread": 3,
      "CWE134_Uncontrolled_Format_String": 4,
      "CWE190_Integer_Overflow": 5,
      "CWE191_Integer_Underflow": 6,
      "CWE194_Unexpected_Sign_Extension": 7,
      "CWE195_Signed_to_Unsigned_Conversion_Error": 8,
      "CWE197_Numeric_Truncation_Error": 9,
      "CWE23_Relative_Path_Traversal": 10,
      "CWE369_Divide_by_Zero": 11,
      "CWE36_Absolute_Path_Traversal": 12,
      "CWE400_Resource_Exhaustion": 13,
      "CWE401_Memory_Leak": 14,
      "CWE415_Double_Free": 15,
      "CWE457_Use_of_Uninitialized_Variable": 16,
      "CWE590_Free_Memory_Not_on_Heap": 17,
      "CWE690_NULL_Deref_From_Return": 18,
      "CWE762_Mismatched_Memory_Management_Routines": 19,
      "CWE789_Uncontrolled_Mem_Alloc": 20,
      "CWE78_OS_Command_Injection": 21
   }
   ```

2. **Pipeline de Treinamento (`train_model.py`):**  
   Este script realiza o carregamento e o pr√©-processamento dos dados, utilizando modelos Word2Vec para transformar o c√≥digo-fonte em vetores num√©ricos. Em seguida, treina um modelo de classifica√ß√£o Random Forest com esses vetores para identificar vulnerabilidades em c√≥digos C/C++. Al√©m disso, o script gera arquivos JSON contendo os vetores processados, os r√≥tulos correspondentes e o mapeamento de falhas (CWE), que podem ser utilizados para etapas posteriores de classifica√ß√£o e an√°lise.

   **Execu√ß√£o:**
   ```
   python3 train_model.py --base_path <diret√≥rio_dos_dados> --minFiles <n√∫mero_m√≠nimo_de_arquivos> --maxFiles <n√∫mero_m√°ximo_de_arquivos>
   ```
   ```json
   [
    [
        0.12609584629535675,
        -1.8871763944625854,
        0.859345555305481,
        0.39093509316444397,
        -0.8027384281158447,
        1.0338129997253418,
        -0.6320635676383972,
        1.360384225845337,
        -0.11257253587245941,
        0.5287671685218811,
        -0.0769924744963646,
        0.1340981423854828,
        -0.7386022806167603,
        0.22158850729465485,
        -0.0841221883893013,
        1.1517157554626465,
        -1.2060550451278687,
        ...
   ```

3. **Classificador (`classify.py`):**  
   Este script classifica arquivos de c√≥digo C++ em categorias de falhas de seguran√ßa (CWEs) previamente treinadas, utilizando modelos de aprendizado de m√°quina como Random Forest ou CodeBERT. Ele processa o c√≥digo, transforma tokens em vetores num√©ricos com um modelo Word2Vec e verifica o mapeamento de r√≥tulos para identificar vulnerabilidades. Com suporte √† an√°lise de m√∫ltiplos arquivos em um diret√≥rio, o script fornece relat√≥rios detalhados de classifica√ß√£o, precis√£o e erros, permitindo a valida√ß√£o eficiente de falhas no c√≥digo-fonte.

   **Execu√ß√£o:**
   ```
   python3 cwe_classification.py --file non_dataset_code --model random_forest_cwe_classifier.pkl --label_map cwe_label_map.json --word2vec word2vec.model
   ```
## Pipelines

   ### üöÄ **Pipeline do Script `load_and_process_cwe_datasets.py`**
   üìÅ **Coleta de Dados** (Identifica√ß√£o e sele√ß√£o de arquivos `.c` e `.cpp` nas subpastas especificadas)  
   ‚ÄÉ‚ÄÉ‚Üì  
   üßπ **Pr√©-processamento** (An√°lise sint√°tica com Tree-sitter, extra√ß√£o e normaliza√ß√£o de tokens relevantes)  
   ‚ÄÉ‚ÄÉ‚Üì  
   ü§ñ **Treinamento de Modelos de Embeddings** (Treinamento de modelos Word2Vec para capturar rela√ß√µes sem√¢nticas entre tokens)  
   ‚ÄÉ‚ÄÉ‚Üì  
   üìà **Visualiza√ß√£o de Embeddings** (Redu√ß√£o de dimensionalidade com PCA e plotagem dos embeddings para visualiza√ß√£o)  
   ‚ÄÉ‚ÄÉ‚Üì  
   üíæ **Salvamento de Resultados** (Exporta√ß√£o dos dados processados e dos modelos treinados para arquivos como `cwe_data.json` e `word2vec.model`)  


### üöÄ **Pipeline do Script `train_cwe_model.py`**

üìÅ **Carregamento de Dados** (Importa√ß√£o dos arquivos JSON contendo os c√≥digos e mapeamento de r√≥tulos)  
‚ÄÉ‚ÄÉ‚Üì  
üìä **Vetoriza√ß√£o com Word2Vec** (Convers√£o dos c√≥digos-fonte em vetores num√©ricos utilizando o modelo Word2Vec treinado)  
‚ÄÉ‚ÄÉ‚Üì  
üîÄ **Divis√£o Treino/Teste** (Separa√ß√£o dos dados vetorizados em conjuntos de treino e teste, com possibilidade de estratifica√ß√£o)  
‚ÄÉ‚ÄÉ‚Üì  
üß† **Treinamento do Random Forest** (Treinamento do classificador Random Forest com os dados de treino)  
‚ÄÉ‚ÄÉ‚Üì  
üìà **Avalia√ß√£o do Modelo** (Gera√ß√£o de relat√≥rio de classifica√ß√£o e matriz de confus√£o para avaliar o desempenho do modelo)  
‚ÄÉ‚ÄÉ‚Üì  
üíæ **Salvamento do Modelo** (Exporta√ß√£o do modelo Random Forest treinado para um arquivo `.pkl` para uso futuro)


## Descri√ß√£o T√©cnica

O modelo foi treinado utilizando um conjunto de dados contendo c√≥digos C/C++ com falhas de seguran√ßa conhecidas, categorizadas em diferentes tipos de vulnerabilidades, como buffer overflow, falhas de controle de fluxo, entre outras.

### Vetoriza√ß√£o com Tree-Sitter e Word2Vec
- **Tree-Sitter:** Utilizado para an√°lise sint√°tica e gera√ß√£o de tokens dos c√≥digos.
- **Word2Vec:** Gera vetores de palavras a partir dos tokens processados.
- **Random Forest:** Modelo de classifica√ß√£o que utiliza os vetores gerados para identificar as vulnerabilidades.

## Melhorias no Projeto - Pr√©-processamento

A evolu√ß√£o no pr√©-processamento de c√≥digo representa um marco importante no desenvolvimento do projeto, permitindo uma an√°lise mais detalhada e assertiva. O pr√©-processamento agora conta com dois modos complementares que aprimoram significativamente os embeddings gerados:

### Modo 1: Foco nos Identificadores (Cleyton)

Neste modo, o pr√©-processamento prioriza apenas os elementos sem√¢nticos do c√≥digo, como nomes de vari√°veis, fun√ß√µes e classes. Essa abordagem simplificada √© eficiente para tarefas que dependem exclusivamente da identifica√ß√£o dos componentes principais do c√≥digo, sendo ideal para cen√°rios com menor complexidade.

### Modo 2: Embeddings Enriquecidos (Fausto)

O segundo modo vai al√©m dos identificadores, incorporando elementos sem√¢nticos e estruturais do c√≥digo. Ele inclui:

- **Identificadores:** Vari√°veis, fun√ß√µes, classes.
- **Estruturas de Controle:** Instru√ß√µes como `if`, `for`, e `while`.
- **Diretivas do Pr√©-processador:** Como `#include` e `#define`.
- **Literais:** Strings, n√∫meros e valores espec√≠ficos do c√≥digo.

#### Benef√≠cios
- **Melhor compreens√£o do fluxo de execu√ß√£o.**
- **Capacidade de identificar rela√ß√µes contextuais.**
- **Maior detalhamento dos padr√µes de codifica√ß√£o.**

## Apresenta√ß√£o e Trabalho

### Modelo Random Forest

#### Pipeline de Processamento e Vetoriza√ß√£o de C√≥digo com Tree-Sitter e Word2Vec (DB minimizado)

Foi utilizado o seguinte comando para processar os conjuntos de dados:
```
python3 load_and_process_cwe_datasets.py --base_path /home/fbiaso/dados/Documentos/PLN/C/testcases --maxFiles 16 --minFiles 10
```

#### Distribui√ß√£o das Classes CWE (DB minimizado)

A execu√ß√£o do script gerou uma base de dados cuja distribui√ß√£o das classes pode ser visualizada na imagem abaixo:

<img src="imgs/cwe_class_distribution.png" alt="Distribui√ß√£o das Classes CW" width="100%">

---
#### Exemplo: Treinamento do Modelo // Teste 1 // [test_size=0.3, n_estimators=100, vector_size=100]

O modelo foi treinado utilizando o seguinte comando:
```
python3 ./train_cwe_model.py --data_dir ./ --word2vec_model_path word2vec.model
```

---

#### Exemplo: Treinamento do Modelo // Teste 2 // [test_size=0.3, n_estimators=200, vector_size=100]

O modelo foi treinado utilizando o seguinte comando:
```
 python3 ./train_cwe_model.py --data_dir ./ --word2vec_model_path word2vec.model --test_size 0.3 --random_state 44 --n_estimators 200 --vector_size 100
```

---

#### Resultados Finais (m√©tricas)

Este documento apresenta um relat√≥rio com os par√¢metros de pr√©-processamento, modelo utilizado, acur√°cia geral, e outros detalhes relacionados √† classifica√ß√£o.

| Par√¢metros                                        | Tipo de Pr√©-processamento | Modelo        | Acur√°cia Geral | Quantidade Total de Dados | Quantidade de Classes | M√©todo de Representa√ß√£o  |
|---------------------------------------------------|---------------------------|---------------|----------------|---------------------------|-----------------------|----------------------|
| test_size=0.3, ***n_estimators=50***, vector_size=100  | Tree-Sitter (ABS)         | Random Forest | 80%            | 123                       | 7                     | Word2Vec                 |
| test_size=0.3, ***n_estimators=100***, vector_size=100  | Tree-Sitter (ABS)         | Random Forest | 87%            | 123                       | 7                     | Word2Vec                 |
| test_size=0.3, ***n_estimators=200***, vector_size=100  | Tree-Sitter (ABS)         | Random Forest | 87%            | 123                       | 7                     | Word2Vec                 |
| test_size=0.3, ***n_estimators=1000***, vector_size=100  | Tree-Sitter (ABS)         | Random Forest | 87%            | 123                       | 7                     | Word2Vec                 |
| test_size=0.3, n_estimators=100, ***vector_size=20***  | Tree-Sitter (ABS)         | Random Forest | 83%            | 123                       | 7                     | Word2Vec                 |
| test_size=0.3, n_estimators=100, ***vector_size=40***  | Tree-Sitter (ABS)         | Random Forest | 83%            | 123                       | 7                     | Word2Vec                 |
| test_size=0.3, n_estimators=100, ***vector_size=80***  | Tree-Sitter (ABS)         | Random Forest | 83%            | 123                       | 7                     | Word2Vec                 |
| test_size=0.3, n_estimators=100, ***vector_size=160***  | Tree-Sitter (ABS)         | Random Forest | 83%            | 123                       | 7                     | Word2Vec                 |
| ***test_size=0.1***, n_estimators=100, vector_size=100  | Tree-Sitter (ABS)         | Random Forest | 90%            | 123                       | 7                     | Word2Vec                 |
| ***test_size=0.15***, n_estimators=100, vector_size=100  | Tree-Sitter (ABS)         | Random Forest | 93%            | 123                       | 7                     | Word2Vec                 |
| ***test_size=0.20***, n_estimators=100, vector_size=100  | Tree-Sitter (ABS)         | Random Forest | 90%            | 123                       | 7                     | Word2Vec                 |
| ***test_size=0.16***, n_estimators=100, vector_size=100  | Tree-Sitter (ABS)         | Random Forest | 100%            | 123                       | 7                     | Word2Vec                 |

---
### Adicionando Estratifica√ß√£o

#### Pipeline de Processamento e Vetoriza√ß√£o de C√≥digo com Tree-Sitter e Word2Vec (DB ~ 1000 arquivos/categoria)

Foi utilizado o seguinte comando para processar os conjuntos de dados:
```
python3 load_and_process_cwe_datasets.py --base_path /home/fbiaso/dados/Documentos/PLN/C/testcases --minFiles 1000 --maxFiles 1200
```

#### Distribui√ß√£o das Classes CWE (DB ~ 1000 arquivos/categoria)

---
#### Exemplo: Treinamento do Modelo // Teste 1 // [test_size=0.3, n_estimators=100, vector_size=100]

O modelo foi treinado utilizando o seguinte comando:
```
python3 ./train_cwe_model.py --data_dir ./ --word2vec_model_path word2vec.model
```

---

#### Exemplo: Treinamento do Modelo // Teste 2 // [test_size=0.3, n_estimators=200, vector_size=100]

O modelo foi treinado utilizando o seguinte comando:
```
 python3 ./train_cwe_model.py --data_dir ./ --word2vec_model_path word2vec.model --test_size 0.3 --random_state 44 --n_estimators 200 --vector_size 100 -stratification yes
```
---

#### Resultados Finais com estratifica√ß√£o (m√©tricas)

Este documento apresenta um relat√≥rio com os par√¢metros de pr√©-processamento, modelo utilizado, acur√°cia geral, e outros detalhes relacionados √† classifica√ß√£o.

| Par√¢metros                                        | Tipo de Pr√©-processamento | Modelo        | Acur√°cia Geral | Quantidade Total de Dados | Quantidade de Classes | M√©todo de Representa√ß√£o | Percentual de Acerto| F1-Score |
|---------------------------------------------------|---------------------------|---------------|----------------|---------------------------|-----------------------|--------------------------|----------------------|----------------------|
|test_size=0.3, ***n_estimators=50***, vector_size=100  | Tree-Sitter (ABS)         | Random Forest | 89%           | 26283                       | 21                     | Word2Vec                 | 13,64%                |89%|
|test_size=0.3, ***n_estimators=100***, vector_size=100  | Tree-Sitter (ABS)         | Random Forest | 89%            | 26283                       | 21                     | Word2Vec                 | 18,18%                  |89%|
| test_size=0.3, ***n_estimators=200***, vector_size=100  | Tree-Sitter (ABS)         | Random Forest | 89%            | 26283                       | 21                     | Word2Vec                 | 13,64%                  |89%|
|test_size=0.3, n_estimators=100, ***vector_size=20***  | Tree-Sitter (ABS)         | Random Forest | 83%            | 26283                       | 21                     | Word2Vec                 |  18,18%                   |89%|
|test_size=0.3, n_estimators=100, ***vector_size=40***  | Tree-Sitter (ABS)         | Random Forest | 83%            | 26283                       | 21                     | Word2Vec                 | 18,18%                 |89%|
|test_size=0.3, n_estimators=100, ***vector_size=80***  | Tree-Sitter (ABS)         | Random Forest | 83%            | 26283                       | 21                     | Word2Vec                 | 18,18%                   |89%|
| test_size=0.3, n_estimators=100, ***vector_size=160***  | Tree-Sitter (ABS)         | Random Forest | 83%            | 26283                       | 21                     | Word2Vec                 | 18,18%                  |89%|
| test_size=0.3, ***n_estimators=500***, ***vector_size=300***  | Tree-Sitter (ABS)         | Random Forest | 89%            | 26283                       | 21                     | Word2Vec                 | 9%                  |89%|

#### Descri√ß√£o dos Par√¢metros

- **Par√¢metros**: Configura√ß√µes utilizadas no modelo, como tamanho do teste (`test_size`), n√∫mero de estimadores (`n_estimators`), e tamanho do vetor (`vector_size`).
- **Tipo de Pr√©-processamento**: T√©cnica utilizada para pr√©-processamento dos dados.
- **Modelo**: O modelo de aprendizado de m√°quina utilizado.
- **Acur√°cia Geral**: Percentual de acerto alcan√ßado pelo modelo.
- **Quantidade Total de Dados**: N√∫mero de amostras utilizadas no modelo.
- **Quantidade de Classes**: N√∫mero de classes para a classifica√ß√£o.
- **M√©todo de Representa√ß√£o**: M√©todo usado para representar as palavras.
- **Percentual de Acerto**: Acur√°cia expressa como percentual de acerto.
- **F1-Score**: M√©dia harm√¥nica entre precis√£o e recall.

## Base de dados
- Juliet C/C++ 1.3 Test suite #112
- https://samate.nist.gov/SARD/test-suites/112

## Depend√™ncias

O projeto foi desenvolvido para rodar em **plataforma Ubuntu** e possui as seguintes depend√™ncias:

- **Python 3.x**
- **pip** (gerenciador de pacotes Python)

### Instala√ß√£o das Depend√™ncias

1. **Crie um ambiente virtual:**
    ```
    python3 -m venv tree-sitter-env
    source tree-sitter-env/bin/activate
    ```

2. **Instale as depend√™ncias:**
    ```
    pip install -r requirements.txt
    ```

**Conte√∫do do `requirements.txt`:**
```
tree-sitter
gensim
scikit-learn
transformers
torch
numpy
pandas
```
